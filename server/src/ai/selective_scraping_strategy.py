"""
Strat√©gie de scraping s√©lectif pour PhoenixCare
Approche gradu√©e bas√©e sur l'analyse robots.txt
"""

from typing import Dict, List, Any, Tuple
import logging
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class ScrapingPermissionLevel(Enum):
    VERY_PERMISSIVE = "very_permissive"
    MODERATELY_PERMISSIVE = "moderately_permissive"
    RESTRICTIVE = "restrictive"
    FORBIDDEN = "forbidden"

@dataclass
class GovernmentSite:
    domain: str
    name: str
    permission_level: ScrapingPermissionLevel
    allowed_paths: List[str]
    forbidden_paths: List[str]
    content_types: List[str]
    priority: int  # 1=high, 5=low
    legal_notes: str
    contact_email: str = ""

class SelectiveScrapingStrategy:
    """
    Gestionnaire de strat√©gie de scraping s√©lectif
    """

    def __init__(self):
        self.government_sites = self._initialize_site_configs()

    def _initialize_site_configs(self) -> Dict[str, GovernmentSite]:
        """
        Configuration des sites gouvernementaux par niveau de permission
        """
        return {
            "legifrance.gouv.fr": GovernmentSite(
                domain="legifrance.gouv.fr",
                name="L√©gifrance",
                permission_level=ScrapingPermissionLevel.VERY_PERMISSIVE,
                allowed_paths=[
                    "/codes/texte_lc/LEGITEXT000006074069",  # Code action sociale
                    "/codes/article_lc/",  # Articles codes
                    "/jorf/",  # Journal officiel
                    "/eli/",  # Identifiants europ√©ens
                ],
                forbidden_paths=["/download/"],
                content_types=["Code CASF", "Jurisprudence", "D√©crets", "Arr√™t√©s"],
                priority=1,
                legal_notes="Tr√®s permissif - seul /download/ interdit. Donn√©es juridiques publiques.",
                contact_email="contact@legifrance.gouv.fr"
            ),

            "service-public.fr": GovernmentSite(
                domain="service-public.fr",
                name="Service Public",
                permission_level=ScrapingPermissionLevel.MODERATELY_PERMISSIVE,
                allowed_paths=[
                    "/particuliers/vosdroits/",  # Fiches droits
                    "/associations/",  # Guides associations
                    "/professionnels/",  # Info pros
                ],
                forbidden_paths=[
                    "/compte/", "/contact/", "/recherche/",
                    "/*?xtor=",  # Tracking URLs
                ],
                content_types=["Fiches pratiques", "Guides d√©marches", "FAQ"],
                priority=2,
                legal_notes="Mod√©r√©ment permissif - √©viter admin/tracking. Fiches publiques OK.",
                contact_email="contact@service-public.fr"
            ),

            "handicap.gouv.fr": GovernmentSite(
                domain="handicap.gouv.fr",
                name="Secr√©tariat Handicap",
                permission_level=ScrapingPermissionLevel.MODERATELY_PERMISSIVE,
                allowed_paths=[
                    "/actualites/",
                    "/droits-et-aides/",
                    "/scolarite-et-handicap/",
                    "/emploi-et-handicap/"
                ],
                forbidden_paths=["/admin/", "/user/"],
                content_types=["Actualit√©s", "Guides droits", "Scolarit√©", "Emploi"],
                priority=1,
                legal_notes="Site sp√©cialis√© handicap - contenu tr√®s pertinent. Pas de robots.txt strict.",
                contact_email="contact@handicap.gouv.fr"
            ),


            "caf.fr": GovernmentSite(
                domain="caf.fr",
                name="CAF",
                permission_level=ScrapingPermissionLevel.RESTRICTIVE,
                allowed_paths=["/particuliers/aides-et-demarches/"],
                forbidden_paths=["/mon-compte/", "/simulateur/"],
                content_types=["Aides familiales", "AEEH"],
                priority=3,
                legal_notes="Restrictif - √©viter simulateurs/comptes. Infos aides OK.",
                contact_email="contact@caf.fr"
            )
        }

    def get_scraping_strategy(self) -> Dict[str, Any]:
        """
        Retourne la strat√©gie de scraping recommand√©e
        """
        strategy = {
            "phase_1_immediate": {
                "manual_ingestion": {
                    "priority": "HIGH",
                    "sources": [
                        "PDFs MDPH locaux",
                        "Guides associations (UNAPEI, APF, etc.)",
                        "Formulaires t√©l√©charg√©s manuellement",
                        "Documentation administrative existante"
                    ],
                    "estimated_documents": "50-100",
                    "timeline": "1-2 semaines"
                },
                "permissive_scraping": {
                    "sites": ["legifrance.gouv.fr", "service-public.fr", "handicap.gouv.fr"],
                    "estimated_pages": "500-1000",
                    "timeline": "2-3 semaines",
                    "legal_risk": "TR√àS FAIBLE"
                }
            },

            "phase_2_selective": {
                "moderate_sites": {
                    "sites": ["caf.fr"],
                    "approach": "Contenu HTML uniquement, pas de docs",
                    "timeline": "1 semaine",
                    "legal_risk": "FAIBLE"
                }
            },

            "phase_3_expansion": {
                "additional_sources": {
                    "approach": "Upload manuel documents sp√©cialis√©s",
                    "sources": ["Associations partenaires", "MDPH d√©partementales", "Guides terrain"],
                    "timeline": "Continu",
                    "legal_risk": "NUL"
                }
            }
        }
        return strategy

    def get_immediate_scraping_list(self) -> List[GovernmentSite]:
        """
        Sites √† scraper imm√©diatement (faible risque)
        """
        safe_sites = []

        for site in self.government_sites.values():
            if site.permission_level in [
                ScrapingPermissionLevel.VERY_PERMISSIVE,
                ScrapingPermissionLevel.MODERATELY_PERMISSIVE
            ] and site.priority <= 2:
                safe_sites.append(site)

        # Tri par priorit√©
        safe_sites.sort(key=lambda x: x.priority)
        return safe_sites

    def get_contact_list_for_authorization(self) -> List[Dict[str, str]]:
        """
        Liste des contacts pour demandes d'autorisation
        """
        contact_list = []

        restrictive_sites = [
            site for site in self.government_sites.values()
            if site.permission_level == ScrapingPermissionLevel.RESTRICTIVE
        ]

        for site in restrictive_sites:
            contact_list.append({
                "domain": site.domain,
                "name": site.name,
                "email": site.contact_email,
                "priority_content": ", ".join(site.content_types),
                "email_template": self._generate_email_template(site)
            })

        return contact_list

    def _generate_email_template(self, site: GovernmentSite) -> str:
        """
        G√©n√®re un template d'email de demande d'autorisation
        """
        return f"""
Objet : Demande d'autorisation - Indexation donn√©es publiques - Projet PhoenixCare

Madame, Monsieur,

PhoenixCare d√©veloppe une assistance IA gratuite et open-source destin√©e √†
accompagner les familles d'enfants en situation de handicap dans leurs
d√©marches administratives complexes.

Nous sollicitons votre autorisation pour indexer automatiquement les contenus
publics de {site.name} ({site.domain}), sp√©cifiquement :
{chr(10).join(f"- {content}" for content in site.content_types)}

Notre approche technique respecte :
- Rate limiting (1 requ√™te/3 secondes)
- Robots.txt et CGU
- Pas de donn√©es personnelles
- Usage exclusivement social/√©ducatif

Objectif : Permettre aux familles d'acc√©der rapidement aux bonnes informations
juridiques via IA conversationnelle, r√©duisant ainsi les d√©lais et erreurs
dans les d√©marches.

Seriez-vous disponible pour un √©change t√©l√©phonique afin de pr√©senter le projet ?

Cordialement,
[Nom]
PhoenixCare - Assistance IA pour l'inclusion
[Email] - [T√©l√©phone]
        """

    def generate_scraping_config(self) -> Dict[str, Any]:
        """
        G√©n√®re la configuration technique pour le scraping s√©lectif
        """
        immediate_sites = self.get_immediate_scraping_list()

        config = {
            "immediate_scraping": {
                "enabled_domains": [site.domain for site in immediate_sites],
                "rate_limits": {
                    site.domain: {
                        "requests_per_second": 0.33,  # 1 req/3s
                        "concurrent_requests": 1,
                        "respect_robots_txt": True
                    } for site in immediate_sites
                },
                "allowed_paths": {
                    site.domain: site.allowed_paths for site in immediate_sites
                },
                "forbidden_paths": {
                    site.domain: site.forbidden_paths for site in immediate_sites
                }
            },
            "manual_ingestion": {
                "upload_directory": "data/manual_uploads/",
                "supported_formats": [".pdf", ".doc", ".docx", ".txt"],
                "max_file_size": "50MB",
                "batch_processing": True
            },
            "monitoring": {
                "compliance_logging": True,
                "performance_tracking": True,
                "legal_audit_trail": True
            }
        }

        return config

# Instance globale pour utilisation
scraping_strategy = SelectiveScrapingStrategy()

# Exemple d'utilisation
if __name__ == "__main__":
    strategy = scraping_strategy.get_scraping_strategy()
    print("=== STRAT√âGIE DE SCRAPING S√âLECTIF ===")

    print("\nüü¢ Phase 1 - Imm√©diat (Faible risque):")
    immediate_sites = scraping_strategy.get_immediate_scraping_list()
    for site in immediate_sites:
        print(f"- {site.name} ({site.domain}) - {site.permission_level.value}")

    print("\nüìß Sites n√©cessitant autorisation:")
    contacts = scraping_strategy.get_contact_list_for_authorization()
    for contact in contacts:
        print(f"- {contact['name']} : {contact['email']}")

    print("\n‚öôÔ∏è Configuration technique g√©n√©r√©e ‚úì")