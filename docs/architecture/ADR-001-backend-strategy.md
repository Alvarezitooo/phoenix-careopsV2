# ADR-001 : StratÃ©gie Backend - Architecture Hybride TypeScript + Python

**Date** : 2025-10-01
**Statut** : âœ… ACCEPTÃ‰
**DÃ©cideurs** : Lead Architect (Kevin), Product Owner
**Contexte** : Sprint 0 - BLOC 2 (Architecture Decision)

---

## ğŸ“‹ Contexte

PhoenixCare possÃ¨de actuellement **2 backends distincts** :

### ğŸŸ¦ Backend TypeScript (`server/src/`)
- **Port** : 3080 (production) / 3000 (dev)
- **Framework** : Express.js + Next.js SSR
- **RÃ´le actuel** :
  - Authentification (Supabase)
  - API REST mÃ©tier (`/api/aides`, `/api/documents`, `/api/procedures`)
  - Orchestration des requÃªtes
  - Server-Side Rendering Next.js
- **Fichiers** : 23 fichiers TypeScript
- **DÃ©pendances** : Express, Supabase, Zod, Winston, Helmet

### ğŸ Backend Python (`server/simple_rag_server.py`)
- **Port** : 8000
- **Framework** : Flask + Google Gemini AI
- **RÃ´le actuel** :
  - SystÃ¨me RAG (Retrieval Augmented Generation)
  - GÃ©nÃ©ration de rÃ©ponses IA empathiques
  - Analyse de documents (PDF, images via Vision)
  - Base de connaissances (29 documents MDPH/CAF)
  - Cache intelligent in-memory
- **Fichiers** : 24 fichiers Python (dont 14 dans `src/ai/`)
- **DÃ©pendances** : Flask, Gemini AI, FAISS, LangChain

### ğŸ”— Communication actuelle
```
Client (Next.js) â†’ TypeScript (3080) â†’ Python (8000)
                      â†“
                   Supabase
```

Le backend TypeScript fait office de **proxy/orchestrateur** et appelle le serveur Python pour le RAG :
```typescript
// server/src/api/chat/service.ts:2
const FASTAPI_BASE_URL = process.env.PYTHON_API_URL || 'http://localhost:8000';
```

---

## ğŸ¯ ProblÃ¨me

Cette architecture "schizophrÃ¨ne" pose plusieurs **risques critiques** :

### âŒ ProblÃ¨mes identifiÃ©s

1. **ComplexitÃ© opÃ©rationnelle**
   - 2 serveurs Ã  dÃ©ployer sÃ©parÃ©ment
   - 2 processus Ã  monitorer
   - 2 systÃ¨mes de logs diffÃ©rents
   - Gestion de dÃ©pendances double (npm + pip)

2. **Points de dÃ©faillance multiples**
   - Si Python crash â†’ chat IA indisponible (service critique)
   - Communication HTTP entre services â†’ latence + risque rÃ©seau
   - Pas de circuit breaker ni retry intelligents

3. **CoÃ»ts de dÃ©ploiement**
   - 2 containers Ã  provisionner
   - Bande passante interne consommÃ©e
   - Configuration rÃ©seau complexe (CORS, ports, DNS interne)

4. **Maintenance difficile**
   - Code dupliquÃ© (validation, logs, erreurs)
   - Synchronisation des schÃ©mas de donnÃ©es
   - Debugging cross-service complexe

5. **ScalabilitÃ© limitÃ©e**
   - Impossible de scaler indÃ©pendamment les endpoints
   - Pas de load balancing par feature
   - Goulot d'Ã©tranglement sur le proxy TypeScript

---

## ğŸ¤” Options considÃ©rÃ©es

### Option A : Monolithe TypeScript (tout migrer en TS)
**Avantages** :
- Un seul langage, une seule stack
- DÃ©ploiement simplifiÃ©
- Debugging unifiÃ©

**InconvÃ©nients** :
- âŒ **BLOQUANT** : Ã‰cosystÃ¨me IA TypeScript limitÃ©
- Gemini SDK Node.js moins mature que Python
- Pas d'Ã©quivalent Ã  LangChain/FAISS en TypeScript
- RÃ©Ã©criture complÃ¨te du RAG = 3-4 semaines (hors sprint)
- Perte de performance (Python meilleur pour ML/vectoriel)

**Verdict** : âŒ RejetÃ© (blocage technique majeur)

---

### Option B : Monolithe Python (tout migrer en Python)
**Avantages** :
- Ã‰cosystÃ¨me IA complet (Gemini, FAISS, LangChain)
- Un seul serveur
- Meilleur pour ML/vectoriel

**InconvÃ©nients** :
- âŒ RÃ©Ã©criture complÃ¨te de l'API REST TypeScript
- Perte de l'intÃ©gration Next.js (SSR complexe en Python)
- Supabase SDK Python moins riche que TypeScript
- Pas de Zod (validation Python moins mature)
- RÃ©Ã©criture = 2-3 semaines (hors sprint)

**Verdict** : âŒ RejetÃ© (perte SSR + rÃ©Ã©criture trop longue)

---

### Option C : Microservices complets (dÃ©coupage par domaine)
**Architecture proposÃ©e** :
```
- Service Auth (TypeScript)
- Service Chat/RAG (Python)
- Service Documents (TypeScript)
- Service Procedures (TypeScript)
- API Gateway (Kong/Traefik)
```

**Avantages** :
- ScalabilitÃ© indÃ©pendante par service
- Isolation des pannes
- Teams autonomes possibles

**InconvÃ©nients** :
- âŒ **Over-engineering** pour une Ã©quipe de 1-2 devs
- Infrastructure complexe (Gateway, Service Discovery, Observability)
- CoÃ»ts d'infra multipliÃ©s
- Debugging distribuÃ© = cauchemar
- Temps de setup = 1 semaine complÃ¨te
- Risque de latence inter-services

**Verdict** : âŒ RejetÃ© (trop complexe pour la taille du projet)

---

### Option D : âœ… Architecture Hybride avec Microservices LÃ©ger (BFF Pattern)

**Architecture recommandÃ©e** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT (Next.js)                     â”‚
â”‚                   localhost:3000                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸŸ¦ BACKEND FOR FRONTEND (BFF)              â”‚
â”‚                    TypeScript Express                   â”‚
â”‚                     Port 3080 (prod)                    â”‚
â”‚                                                         â”‚
â”‚  ResponsabilitÃ©s :                                      â”‚
â”‚  â€¢ Authentification (Supabase)                          â”‚
â”‚  â€¢ Authorization & Session management                   â”‚
â”‚  â€¢ API REST mÃ©tier (/api/aides, /documents, /procedures)â”‚
â”‚  â€¢ Orchestration & composition de donnÃ©es              â”‚
â”‚  â€¢ Server-Side Rendering (Next.js)                     â”‚
â”‚  â€¢ Rate limiting & CORS                                 â”‚
â”‚  â€¢ Logging unifiÃ© (Winston)                            â”‚
â”‚  â€¢ Error handling standardisÃ©                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“                                 â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Supabase    â”‚              â”‚  ğŸ AI Service   â”‚
    â”‚               â”‚              â”‚  Python Flask    â”‚
    â”‚  â€¢ Auth       â”‚              â”‚   Port 8000      â”‚
    â”‚  â€¢ PostgreSQL â”‚              â”‚                  â”‚
    â”‚  â€¢ Storage    â”‚              â”‚  ResponsabilitÃ©s:â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â€¢ RAG (Gemini)  â”‚
                                   â”‚  â€¢ Vectorisation â”‚
                                   â”‚  â€¢ Doc Analysis  â”‚
                                   â”‚  â€¢ Vision AI     â”‚
                                   â”‚  â€¢ Cache smart   â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- âœ… **SÃ©paration des responsabilitÃ©s claire**
  - BFF TypeScript : MÃ©tier + Auth + Orchestration
  - AI Service Python : IA + ML + Vectoriel
- âœ… **Utilise les forces de chaque langage**
  - TypeScript : API REST, validation Zod, Supabase, SSR
  - Python : Gemini, FAISS, LangChain, ML
- âœ… **ScalabilitÃ© ciblÃ©e**
  - Scaler AI Service sÃ©parÃ©ment (goulet IA identifiÃ©)
  - BFF reste lÃ©ger et rÃ©actif
- âœ… **DÃ©ploiement pragmatique**
  - 2 containers seulement
  - Communication interne (pas CORS public)
  - Monitoring centralisÃ© via BFF
- âœ… **Ã‰volutivitÃ©**
  - Facile d'extraire d'autres services plus tard
  - Pattern BFF permet composition flexible
- âœ… **Pas de rÃ©Ã©criture**
  - Architecture actuelle dÃ©jÃ  proche de ce pattern
  - Refactoring lÃ©ger suffisant

**InconvÃ©nients mineurs** :
- âš ï¸ 2 serveurs Ã  dÃ©ployer (acceptable)
- âš ï¸ Communication HTTP interne (latence <5ms en local network)

**Verdict** : âœ… **ACCEPTÃ‰**

---

## ğŸ“ DÃ©cision

**Nous adoptons l'Architecture Hybride avec BFF Pattern (Option D)** pour les raisons suivantes :

### ğŸ¯ Justifications techniques

1. **Pragmatisme**
   - Architecture actuelle dÃ©jÃ  proche de ce pattern
   - Refactoring lÃ©ger suffisant (pas de rÃ©Ã©criture complÃ¨te)
   - Livrable dans Sprint 0 (quelques heures)

2. **SÃ©paration des prÃ©occupations**
   - BFF TypeScript : Porte d'entrÃ©e unique, sÃ©curitÃ©, orchestration
   - AI Service Python : SpÃ©cialisÃ© IA/ML (core business)

3. **Performance**
   - TypeScript excellent pour I/O (API REST, Supabase)
   - Python optimal pour calculs vectoriels (FAISS, embeddings)

4. **MaintenabilitÃ©**
   - 2 services clairement dÃ©finis
   - Contrats d'API explicites entre BFF et AI Service
   - Logs centralisÃ©s via BFF

5. **ScalabilitÃ© future**
   - AI Service peut Ãªtre scaler indÃ©pendamment (cache Redis futur)
   - BFF reste stable et rÃ©actif
   - Pattern extensible vers plus de microservices si besoin

---

## ğŸš€ Plan d'implÃ©mentation

### Phase 1 : Refactoring actuel (Sprint 0)
- [x] Renommer `server.ts` â†’ `bff.ts` (clartÃ©)
- [x] Ajouter commentaires architecture dans les 2 serveurs
- [x] Documenter les contrats d'API (BFF â†” AI Service)
- [x] Standardiser les env vars (PYTHON_API_URL)
- [x] Ajouter retry logic sur appels AI Service (circuit breaker simple)

### Phase 2 : AmÃ©lioration monitoring (Sprint 1)
- [ ] Logs structurÃ©s JSON uniformes
- [ ] Health checks dÃ©taillÃ©s (/healthz avec dÃ©pendances)
- [ ] MÃ©triques Prometheus (latence, erreurs, cache hit rate)
- [ ] Alerting basique (si AI Service down)

### Phase 3 : Optimisation communication (Sprint 2)
- [ ] Communication gRPC (au lieu de HTTP/JSON)
- [ ] Cache partagÃ© Redis entre BFF et AI Service
- [ ] Load balancing AI Service (si besoin scale)

---

## ğŸ”’ Contrats d'API

### BFF â†’ AI Service

**Endpoint** : `POST http://localhost:8000/api/chat/send`

**Request** :
```json
{
  "message": "Bonjour, je voudrais des infos sur l'AEEH",
  "user_id": "uuid",
  "conversation_history": [],
  "user_context": {}
}
```

**Response** :
```json
{
  "answer": "L'AEEH (Allocation d'Ã‰ducation de l'Enfant HandicapÃ©)...",
  "conversation_id": "conv_uuid_timestamp",
  "processing_time": 1.23,
  "sources": [
    { "title": "AEEH - CAF", "url": "..." }
  ]
}
```

**SLA** :
- Timeout : 30 secondes
- Retry : 2 tentatives avec backoff exponentiel
- Fallback : Message d'erreur empathique si Ã©chec

---

## ğŸ“Š MÃ©triques de succÃ¨s

| MÃ©trique | Objectif Sprint 0 | Objectif Sprint 2 |
|----------|-------------------|-------------------|
| Latence BFFâ†’AI | < 50ms | < 20ms |
| Latence AI (gÃ©nÃ©ration) | < 3s | < 2s |
| DisponibilitÃ© AI Service | 99% | 99.9% |
| Cache hit rate | 30% | 60% |
| Temps dÃ©ploiement | < 5min | < 2min |

---

## ğŸ”„ Revue future

**Date de revue** : Sprint 2 (fin octobre 2025)

**CritÃ¨res de rÃ©ussite** :
- [ ] 0 incidents liÃ©s Ã  la communication BFFâ†”AI
- [ ] Latence P95 < 3 secondes end-to-end
- [ ] Cache hit rate > 40%
- [ ] DÃ©ploiement automatisÃ© (CI/CD)

**CritÃ¨res de rÃ©Ã©valuation** :
- Si cache hit < 20% â†’ considÃ©rer cache Redis partagÃ©
- Si latence P95 > 5s â†’ profiler et optimiser AI Service
- Si incidents communication > 5/mois â†’ considÃ©rer gRPC ou message queue

---

## ğŸ“š RÃ©fÃ©rences

- [Backend for Frontend Pattern (Sam Newman)](https://samnewman.io/patterns/architectural/bff/)
- [Microservices vs Monoliths (Martin Fowler)](https://martinfowler.com/articles/microservices.html)
- [Python for ML, TypeScript for APIs (Stack Overflow Survey 2024)](https://survey.stackoverflow.co/)

---

**SignÃ©** : Lead Architect (Kevin) & Product Owner
**Date** : 2025-10-01
